{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWkqBpY6T3Yu",
        "outputId": "95ca4edb-0d06-444a-d713-dda28c9a70b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import os                    # Operating system-related functions\n",
        "import pandas as pd          # Data manipulation and analysis library\n",
        "import requests              # HTTP library for making web requests\n",
        "from bs4 import BeautifulSoup  # Library for parsing HTML and XML documents\n",
        "import numpy as np           # Numerical computing library\n",
        "from google.colab import files  # Library for interacting with files in Google Colab\n",
        "import nltk                  # Natural Language Toolkit for text processing\n",
        "from nltk.tokenize import word_tokenize  # Tokenization function from NLTK\n",
        "from nltk.corpus import stopwords      # Stopwords from NLTK for text preprocessing\n",
        "nltk.download('punkt')       # Download NLTK's punkt tokenizer data (punctuations)\n",
        "nltk.download('stopwords')   # Download NLTK's stopwords data\n",
        "import re                    # Regular expressions library for text processing\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the 'drive' module from 'google.colab' library\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive to the '/content/drive' directory in Colab\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "dYXcaS3ThC9u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0272016-e91e-4d71-ec2f-4a4fb1150c4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_excel('/content/drive/MyDrive/Assignment/Input.xlsx')[['URL_ID','URL']]"
      ],
      "metadata": {
        "id": "Mod1ssT1hFnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select and create a new DataFrame containing the first 150 rows of the original 'df'.\n",
        "# The original 'df' remains unchanged.\n",
        "df = df.iloc[0:150]"
      ],
      "metadata": {
        "id": "iwZGzfZWjPqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "3_N-TOJqmfBY",
        "outputId": "92028f1f-37ea-4bf6-c08b-519c0597b1f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     URL_ID                                                URL\n",
              "0        37  https://insights.blackcoffer.com/ai-in-healthc...\n",
              "1        38  https://insights.blackcoffer.com/what-if-the-c...\n",
              "2        39  https://insights.blackcoffer.com/what-jobs-wil...\n",
              "3        40  https://insights.blackcoffer.com/will-machine-...\n",
              "4        41  https://insights.blackcoffer.com/will-ai-repla...\n",
              "..      ...                                                ...\n",
              "109     146  https://insights.blackcoffer.com/blockchain-fo...\n",
              "110     147  https://insights.blackcoffer.com/the-future-of...\n",
              "111     148  https://insights.blackcoffer.com/big-data-anal...\n",
              "112     149  https://insights.blackcoffer.com/business-anal...\n",
              "113     150  https://insights.blackcoffer.com/challenges-an...\n",
              "\n",
              "[114 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1c28cb66-f969-4dd4-a3d3-d5e758f35c59\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>URL_ID</th>\n",
              "      <th>URL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>37</td>\n",
              "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>38</td>\n",
              "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>39</td>\n",
              "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>40</td>\n",
              "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>41</td>\n",
              "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>146</td>\n",
              "      <td>https://insights.blackcoffer.com/blockchain-fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>147</td>\n",
              "      <td>https://insights.blackcoffer.com/the-future-of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>148</td>\n",
              "      <td>https://insights.blackcoffer.com/big-data-anal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>149</td>\n",
              "      <td>https://insights.blackcoffer.com/business-anal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>150</td>\n",
              "      <td>https://insights.blackcoffer.com/challenges-an...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>114 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1c28cb66-f969-4dd4-a3d3-d5e758f35c59')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1c28cb66-f969-4dd4-a3d3-d5e758f35c59 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1c28cb66-f969-4dd4-a3d3-d5e758f35c59');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-05e14e88-c489-4ed2-87dd-707f558f6c02\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-05e14e88-c489-4ed2-87dd-707f558f6c02')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-05e14e88-c489-4ed2-87dd-707f558f6c02 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop('URL_ID',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "5qEHt4csmlrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read data from an Excel file (assuming it contains a 'URL' column and a 'URL_ID' column)\n",
        "df = pd.read_excel('/content/drive/MyDrive/Assignment/Input.xlsx')\n",
        "\n",
        "# Loop through each row in the DataFrame\n",
        "for index, row in df.iterrows():\n",
        "    # Extract URL and URL_ID from the current row\n",
        "    url = row['URL']\n",
        "    url_id = row['URL_ID']\n",
        "\n",
        "    # Make an HTTP request to the URL with a user-agent header\n",
        "    header = {\n",
        "        'User-Agent': \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36\"\n",
        "    }\n",
        "    try:\n",
        "        response = requests.get(url, headers=header)\n",
        "    except:\n",
        "        # Handle exceptions if there's an issue with the request\n",
        "        print(\"Can't get response of {}\".format(url_id))\n",
        "\n",
        "    # Create a BeautifulSoup object to parse the HTML content of the page\n",
        "    try:\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    except:\n",
        "        # Handle exceptions if there's an issue with parsing the HTML\n",
        "        print(\"Can't get page of {}\".format(url_id))\n",
        "\n",
        "    # Find the title of the webpage (assuming it's wrapped in an 'h1' tag)\n",
        "    try:\n",
        "        title = soup.find('h1').get_text()\n",
        "    except:\n",
        "        # Handle exceptions if there's an issue with finding the title\n",
        "        print(\"Can't get title of {}\".format(url_id))\n",
        "        continue  # Skip this URL and move to the next one\n",
        "\n",
        "    # Initialize a variable to store the article text\n",
        "    article = \"\"\n",
        "    try:\n",
        "        # Find all 'p' tags and concatenate their text into the 'article' variable\n",
        "        for p in soup.find_all('p'):\n",
        "            article += p.get_text()\n",
        "    except:\n",
        "        # Handle exceptions if there's an issue with extracting the text\n",
        "        print(\"Can't get text of {}\".format(url_id))\n",
        "\n",
        "    # Define the file name where the title and article text will be saved\n",
        "    file_name = '/content/drive/MyDrive/Assignment/TitleText/' + str(url_id) + '.txt'\n",
        "\n",
        "    # Write the title and article text to the file\n",
        "    with open(file_name, 'w') as file:\n",
        "        file.write(title + '\\n' + article)"
      ],
      "metadata": {
        "id": "eiwiwk6Jm3I8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04d9b4a6-c704-44d9-c79e-c42c44d01081"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Can't get title of 44\n",
            "Can't get title of 57\n",
            "Can't get title of 144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Directories where files are located\n",
        "text_dir = \"/content/drive/MyDrive/Assignment/TitleText\"  # Directory for text files\n",
        "stopwords_dir = \"/content/drive/MyDrive/Assignment/StopWords\"  # Directory for stop words\n",
        "sentiment_dir = \"/content/drive/MyDrive/Assignment/MasterDictionary\"  # Directory for sentiment analysis files\n",
        "\n",
        "# Initialize a set to store stop words\n",
        "stop_words = set()\n",
        "\n",
        "# Load stop words from the 'stopwords_dir' directory and add them to the 'stop_words' set\n",
        "for files in os.listdir(stopwords_dir):\n",
        "    with open(os.path.join(stopwords_dir, files), 'r', encoding='ISO-8859-1') as f:\n",
        "        stop_words.update(set(f.read().splitlines()))\n",
        "\n",
        "# Initialize a list to store text from files\n",
        "docs = []\n",
        "\n",
        "# Load text files from the 'text_dir' directory and process them\n",
        "for text_file in os.listdir(text_dir):\n",
        "    with open(os.path.join(text_dir, text_file), 'r') as f:\n",
        "        text = f.read()\n",
        "        # Tokenize the text\n",
        "        words = word_tokenize(text)\n",
        "        # Remove stop words from the tokens\n",
        "        filtered_text = [word for word in words if word.lower() not in stop_words]\n",
        "        # Add filtered tokens to the 'docs' list\n",
        "        docs.append(filtered_text)\n",
        "\n",
        "# Initialize sets to store positive and negative words\n",
        "pos = set()\n",
        "neg = set()\n",
        "\n",
        "# Load positive and negative words from the 'sentiment_dir' directory\n",
        "for files in os.listdir(sentiment_dir):\n",
        "    if files == 'positive-words.txt':\n",
        "        with open(os.path.join(sentiment_dir, files), 'r', encoding='ISO-8859-1') as f:\n",
        "            pos.update(f.read().splitlines())\n",
        "    else:\n",
        "        with open(os.path.join(sentiment_dir, files), 'r', encoding='ISO-8859-1') as f:\n",
        "            neg.update(f.read().splitlines())\n",
        "\n",
        "# Initialize lists to store scores\n",
        "positive_words = []\n",
        "Negative_words = []\n",
        "positive_score = []\n",
        "negative_score = []\n",
        "polarity_score = []\n",
        "subjectivity_score = []\n",
        "\n",
        "# Iterate through the list of documents (tokenized text)\n",
        "# Iterate through the list of documents (tokenized text)\n",
        "for i in range(len(docs)):\n",
        "    # Find words in the current document that are in the 'pos' (positive) set and store them in 'positive_words'\n",
        "    positive_words.append([word for word in docs[i] if word.lower() in pos])\n",
        "\n",
        "    # Find words in the current document that are in the 'neg' (negative) set and store them in 'Negative_words'\n",
        "    Negative_words.append([word for word in docs[i] if word.lower() in neg])\n",
        "\n",
        "    # Calculate the count of positive words in the current document and store it in 'positive_score'\n",
        "    positive_score.append(len(positive_words[i]))\n",
        "\n",
        "    # Calculate the count of negative words in the current document and store it in 'negative_score'\n",
        "    negative_score.append(len(Negative_words[i]))\n",
        "\n",
        "    # Calculate the polarity score for the current document using the formula\n",
        "    # (positive_score - negative_score) / (positive_score + negative_score + 0.000001)\n",
        "    # and store it in 'polarity_score'\n",
        "    polarity_score.append((positive_score[i] - negative_score[i]) / ((positive_score[i] + negative_score[i]) + 0.000001))\n",
        "\n",
        "    # Calculate the subjectivity score for the current document using the formula\n",
        "    # (positive_score + negative_score) / (len(docs[i]) + 0.000001)\n",
        "    # and store it in 'subjectivity_score'\n",
        "    subjectivity_score.append((positive_score[i] + negative_score[i]) / (len(docs[i]) + 0.000001))\n",
        "\n"
      ],
      "metadata": {
        "id": "z0MKyGFBnNtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')  # This downloads the stopwords data\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Average Sentence Length = the number of words / the number of sentences\n",
        "# Percentage of Complex words = the number of complex words / the number of words\n",
        "# Fog Index = 0.4 * (Average Sentence Length + Percentage of Complex words)\n",
        "\n",
        "avg_sentence_length = []\n",
        "Percentage_of_Complex_words  =  []\n",
        "Fog_Index = []\n",
        "complex_word_count =  []\n",
        "avg_syllable_word_count =[]\n",
        "\n",
        "stopwords = set(stopwords.words('english'))\n",
        "def measure(file):\n",
        "  with open(os.path.join(text_dir, file),'r') as f:\n",
        "    text = f.read()\n",
        "# remove punctuations\n",
        "    text = re.sub(r'[^\\w\\s.]','',text)\n",
        "# split the given text file into sentences\n",
        "    sentences = text.split('.')\n",
        "# total number of sentences in a file\n",
        "    num_sentences = len(sentences)\n",
        "# total words in the file\n",
        "    words = [word  for word in text.split() if word.lower() not in stopwords ]\n",
        "    num_words = len(words)\n",
        "\n",
        "# complex words having syllable count is greater than 2\n",
        "# Complex words are words in the text that contain more than two syllables.\n",
        "    complex_words = []\n",
        "    for word in words:\n",
        "      vowels = 'aeiou'\n",
        "      syllable_count_word = sum( 1 for letter in word if letter.lower() in vowels)\n",
        "      if syllable_count_word > 2:\n",
        "        complex_words.append(word)\n",
        "\n",
        "# Syllable Count Per Word\n",
        "# We count the number of Syllables in each word of the text by counting the vowels present in each word.\n",
        "#  We also handle some exceptions like words ending with \"es\",\"ed\" by not counting them as a syllable.\n",
        "# A syllable is a unit of sound in a word, typically consisting of a vowel sound and any accompanying consonant sounds\n",
        "    syllable_count = 0\n",
        "    syllable_words =[]\n",
        "    for word in words:\n",
        "      if word.endswith('es'):\n",
        "        word = word[:-2]\n",
        "      elif word.endswith('ed'):\n",
        "        word = word[:-2]\n",
        "      vowels = 'aeiou'\n",
        "      syllable_count_word = sum( 1 for letter in word if letter.lower() in vowels)\n",
        "      if syllable_count_word >= 1:\n",
        "        syllable_words.append(word)\n",
        "        syllable_count += syllable_count_word\n",
        "\n",
        "\n",
        "    avg_sentence_len = num_words / num_sentences\n",
        "    avg_syllable_word_count = syllable_count / len(syllable_words)\n",
        "    Percent_Complex_words  =  len(complex_words) / num_words\n",
        "    Fog_Index = 0.4 * (avg_sentence_len + Percent_Complex_words)\n",
        "\n",
        "    return avg_sentence_len, Percent_Complex_words, Fog_Index, len(complex_words),avg_syllable_word_count\n",
        "\n",
        "# iterate through each file or doc\n",
        "for file in os.listdir(text_dir):\n",
        "  x,y,z,a,b = measure(file)\n",
        "  avg_sentence_length.append(x)\n",
        "  Percentage_of_Complex_words.append(y)\n",
        "  Fog_Index.append(z)\n",
        "  complex_word_count.append(a)\n",
        "  avg_syllable_word_count.append(b)"
      ],
      "metadata": {
        "id": "THF5bE85K2X-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15c2e58e-4fb4-4eab-f1e4-7e1b60962c24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate word count and average word length for a text file\n",
        "def cleaned_words(file):\n",
        "    with open(os.path.join(text_dir, file), 'r') as f:\n",
        "        text = f.read()\n",
        "\n",
        "        # Remove punctuations from the text\n",
        "        text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "        # Split the text into words and remove stopwords\n",
        "        words = [word for word in text.split() if word.lower() not in stopwords]\n",
        "\n",
        "        # Calculate the total number of characters in all words\n",
        "        length = sum(len(word) for word in words)\n",
        "\n",
        "        # Calculate the average word length\n",
        "        average_word_length = length / len(words)\n",
        "\n",
        "    return len(words), average_word_length\n",
        "\n",
        "# Lists to store word count and average word length\n",
        "word_count = []\n",
        "average_word_length = []\n",
        "\n",
        "# Iterate through each file or document in the directory\n",
        "for file in os.listdir(text_dir):\n",
        "    x, y = cleaned_words(file)\n",
        "    word_count.append(x)\n",
        "    average_word_length.append(y)\n"
      ],
      "metadata": {
        "id": "ZC2_04NANVL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to count personal pronouns in a text file\n",
        "def count_personal_pronouns(file):\n",
        "    with open(os.path.join(text_dir, file), 'r') as f:\n",
        "        text = f.read()\n",
        "        personal_pronouns = [\"I\", \"we\", \"my\", \"ours\", \"us\"]\n",
        "        count = 0\n",
        "        for pronoun in personal_pronouns:\n",
        "            # Using regex to find occurrences of the personal pronoun with word boundaries (\\b)\n",
        "            count += len(re.findall(r\"\\b\" + pronoun + r\"\\b\", text))\n",
        "    return count\n",
        "\n",
        "# List to store the counts of personal pronouns for each file\n",
        "pp_count = []\n",
        "\n",
        "# Iterate through each file or document in the directory\n",
        "for file in os.listdir(text_dir):\n",
        "    x = count_personal_pronouns(file)\n",
        "    pp_count.append(x)\n"
      ],
      "metadata": {
        "id": "EcXKfqLXOlp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate the average number of words per sentence in a text file\n",
        "def calculate_avg_no_of_words_per_sentence(file):\n",
        "    with open(file, 'r') as f:\n",
        "        text = f.read()\n",
        "    sentences = text.split('.')  # Split the text into sentences\n",
        "    num_sentences = len(sentences)\n",
        "    words = [word for word in text.split() if word.lower() not in stopwords]\n",
        "    num_words = len(words)\n",
        "    avg_words_per_sentence = num_words / num_sentences\n",
        "    return avg_words_per_sentence\n",
        "\n",
        "# List to store the average number of words per sentence for each file\n",
        "avg_words_per_sentence_list = []\n",
        "\n",
        "# Iterate through each file or document in the directory\n",
        "for file in os.listdir(text_dir):\n",
        "    file_path = os.path.join(text_dir, file)\n",
        "    avg_words_per_sentence = calculate_avg_no_of_words_per_sentence(file_path)\n",
        "    avg_words_per_sentence_list.append(avg_words_per_sentence)\n",
        "\n",
        "# Calculate the overall average number of words per sentence for all files\n",
        "average_words_per_sentence = sum(avg_words_per_sentence_list) / len(avg_words_per_sentence_list)\n",
        "print(\"Average number of words per sentence:\", average_words_per_sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKhpbpcFTG8b",
        "outputId": "95448544-b7bb-4bc7-cdf1-b8516543c9e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average number of words per sentence: 14.596792377456245\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read data from an Excel file into a DataFrame\n",
        "output_df = pd.read_excel('/content/drive/MyDrive/Assignment/Output Data Structure.xlsx')\n",
        "\n",
        "# URL_ID 44, 57, and 144 do not exist (i.e., the pages do not exist and throw 404 errors),\n",
        "# so we are going to drop these rows from the DataFrame\n",
        "output_df.drop([44-37, 57-37, 144-37], axis=0, inplace=True)\n",
        "\n",
        "# Define the required parameters in a list\n",
        "variables = [positive_score,\n",
        "             negative_score,\n",
        "             polarity_score,\n",
        "             subjectivity_score,\n",
        "             avg_sentence_length,\n",
        "             Percentage_of_Complex_words,\n",
        "             Fog_Index,\n",
        "             avg_words_per_sentence_list,\n",
        "             complex_word_count,\n",
        "             word_count,\n",
        "             avg_syllable_word_count,\n",
        "             pp_count,\n",
        "             average_word_length]\n",
        "\n",
        "# Write the values to the DataFrame\n",
        "for i, var in enumerate(variables):\n",
        "    output_df.iloc[:, i+2] = var\n",
        "\n",
        "# Save the modified DataFrame to a CSV file\n",
        "output_df.to_csv('/content/drive/MyDrive/Assignment/Output.xlsx')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aC1tZPlUO46q",
        "outputId": "910f2a77-f5c8-437c-c033-5a27f62a77ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-6bfd6a3514dc>:25: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
            "  output_df.iloc[:, i+2] = var\n"
          ]
        }
      ]
    }
  ]
}